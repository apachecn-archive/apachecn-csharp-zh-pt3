# 8.视频和声音

要为您的增强现实体验添加另一个互动维度，您可以将声音和视频融入到您的场景中。当它们是与场景中的项目交互的结果时，这尤其有效。

## 播放声音

播放声音是一件非常简单的事情；您只需使用`AVAudioPlayer`的一个实例，向它提供一个声音文件的位置(确保您已经将它添加到您的项目中)，并调用`.Play()`，如清单 [8-1](#PC1) 所示。

```cs
NSUrl songURL = new NSUrl($"Sounds/sound.mp3");
NSError err;
AVAudioPlayer player
    = new AVAudioPlayer(songURL, "Song", out err);
player.Volume = 0.5f;
player.FinishedPlaying += delegate {
    player = null;
};
player.Play();

Listing 8-1Playing sound in an AR scene

```

由于声音是反馈与应用程序交互的一种很好的方式，例如，如果你愿意，你可以在场景中按下`SCNNode`时播放声音。或者你可以在应用首次加载时播放声音。

## 播放视频

你必须看到它才会相信，因为它看起来有点可怕，但你可以在你的增强现实场景中播放视频，这几乎就像虚拟电视屏幕或显示器一样。

在这个例子中，我们需要使用一个`SKVideoNode`和`SKScene`来播放视频。

在清单 [8-2](#PC2) 中，您可以看到我们使用`SCNMaterial`将视频放在 2D 的飞机上。由于这是一种材质，您可以在其他地方使用它，例如，在 3D 盒子的侧面。

```cs
public override void ViewDidAppear(bool animated)
{
    base.ViewDidAppear(animated);
    this.sceneView.Session.Run(new
       ARWorldTrackingConfiguration {
        LightEstimationEnabled = true,
        WorldAlignment = ARWorldAlignment.GravityAndHeading

       });
    var videoNode
      = new SKVideoNode("Videos/big-buck-bunny-wide.mp4");

    // Without this the video will be inverted upside down and
    // back to front
    videoNode.YScale = -1;
    videoNode.Play();

    var videoScene = new SKScene();
    videoScene.Size = new CoreGraphics.CGSize(640, 360);
    videoScene.ScaleMode = SKSceneScaleMode.AspectFill;
    videoNode.Position
      = new CoreGraphics.CGPoint(videoScene.Size.Width / 2,
         videoScene.Size.Height / 2);
    videoScene.AddChild(videoNode);

    // Set to be the same aspect ratio as the video itself
   //(1.77)
    var width = 0.5f;
    var length = 0.28f;

    var material = new SCNMaterial();
    material.Diffuse.Contents = videoScene;
    material.DoubleSided = true;

    var geometry = SCNPlane.Create(width, length);
    geometry.Materials = new[] { material };

    var planeNode = new SCNNode();
    planeNode.Geometry = geometry;
    planeNode.Position = new SCNVector3(0, 0, -0.5f);

    this.sceneView.Scene.RootNode.AddChildNode(planeNode);
}

Listing 8-2Playing video in an AR scene

```

在清单 [8-2](#PC2) 中，您还会注意到我们必须使用 SceneKit 中的一些东西来播放视频，包括`SKScene`和`SKVideoNode.`

在图 [8-1](#Fig1) 中，你可以看到一架漂浮的 2D 飞机如何显示正在播放的视频。甚至有可能改变它的不透明度，使其半透明或产生阴影，如第 [7](07.html) “照明”一章所讨论的

![img/499298_1_En_8_Fig1_HTML.jpg](img/499298_1_En_8_Fig1_HTML.jpg)

图 8-1

在漂浮的 2D 飞机上播放视频

## 要尝试的事情

**同时播放多个视频。**

看看能不能在多个平面节点上同时播放同一个视频文件；然后看看能不能在不同的节点上同时播放不同的视频文件。

看看有多少个节点可以同时完成这项工作。5?50?

在巨大的飞机上播放视频。

梦想过 80 英寸的电视吗？看看你能否通过在一架巨大的 2D 飞机上播放一个电影文件来重现这一场景。

## 摘要

在增强现实体验中使用声音有助于在用户与你的应用程序交互时提供听觉反馈，使用视频有助于吸引用户、娱乐用户或与用户交流。两者都为用户提供了更高水平的参与度。

在下一章中，我们将看看平面检测，它可以识别地面和墙壁等表面。一旦我们探测到这些表面，我们就可以用它们做一些有趣的事情。